# HACKSRM_HELPBRIGHT


># PROJECT DESCRIPTION

There are lot of technology to help people in need whether it is to fight natural disaster or to ease the difficulty of physically challenged people. This project is an health related open inovation to challenge the difficulty faced by visually impaired / blind people. Having an app in the smartphone where you hang the smartphone around the neck and the phone camera can detect all the surrounding and inform you, this could be a lot easier for blind people to walk and get to know about surrounding environment. 


The project is about creating an android app for blind people or visually impaired people and those who are not able to talk, that can sense the surrounding and detect the object like human, chair, tree, path, etc and gives voice guidance. We have integrate text-speech api which converts object detected - text into speech. It also measure whether the object is far or near and give voice accordingly. We have trained the model with coco dataset and ssd mobilenet v2 and yolo. Beside that it has proximity sensor to sense the surrounding and vibration functionalities when object detected.plus we even enabled the mobile proximity sensor so that if there is something near to the sensor or the phone, the person will get an Alert command with the viberation. we can even implement this logic to the stick so that the person always gets alert whenever there is some obstacles. 


An app to help guide blind people in walking.An android/ios app that can help people with visual problems to navigate through crowd better. Phone's camera can be used to see if people are coming on a footpath and give voice instructions to user to change their direction. We can also set the field to 360 degree cameras which will help better navigation as tech gets cheaper. 

***

># RELEVANT TECHNOLOGY
* AI/ ML 
* Voice Assistant
* TensorFlow
* Android

***

